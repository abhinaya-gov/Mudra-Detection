{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcc9be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "MODEL_PATH = \"hand_model_mudra_green_10_me.pth\"  # path to your saved model\n",
    "INPUT_SIZE = 416                           # resize camera frames to this\n",
    "USE_GPU = torch.mps.is_available()\n",
    "# -----------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MudraCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        def block(inp, out):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(inp, out, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(out),\n",
    "                nn.Conv2d(out, out, 3, padding=1),\n",
    "                nn.ReLU(),\n",
    "                nn.BatchNorm2d(out)\n",
    "            )\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            block(3, 32),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            block(32, 64),\n",
    "            nn.MaxPool2d(2),\n",
    "\n",
    "            block(64, 128),\n",
    "            nn.MaxPool2d(3),\n",
    "\n",
    "            block(128, 256),\n",
    "            nn.MaxPool2d(3),\n",
    "\n",
    "            block(256, 256),\n",
    "            nn.MaxPool2d(3),\n",
    "\n",
    "            # nn.AdaptiveAvgPool2d(3)\n",
    "        )\n",
    "        self.fc = nn.Linear(256*3*3, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"\n",
    "    Load model and class names from checkpoint.\n",
    "    \"\"\"\n",
    "    checkpoint = torch.load(MODEL_PATH, map_location=\"cpu\")\n",
    "    classes = checkpoint[\"classes\"]\n",
    "\n",
    "    model = MudraCNN(num_classes=len(classes))\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "    model.eval()\n",
    "    if USE_GPU:\n",
    "        model.to(\"mps\")\n",
    "    return model, classes\n",
    "\n",
    "\n",
    "# Preprocessing transform for each frame (matches training)\n",
    "transform = T.Compose([\n",
    "    T.ToPILImage(),\n",
    "    T.Resize((INPUT_SIZE, INPUT_SIZE)),\n",
    "    T.ToTensor(),\n",
    "])\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_frame(model, classes, frame_bgr):\n",
    "    \"\"\"\n",
    "    Takes a BGR frame (from OpenCV), returns (predicted_label, confidence)\n",
    "    \"\"\"\n",
    "    # Convert BGR (OpenCV) → RGB (PyTorch convention)\n",
    "    frame_rgb = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Apply transforms\n",
    "    img = transform(frame_rgb)  # shape: [C, H, W]\n",
    "    img = img.unsqueeze(0)      # shape: [1, C, H, W]\n",
    "\n",
    "    if USE_GPU:\n",
    "        img = img.to(\"mps\")\n",
    "\n",
    "    # Forward pass\n",
    "    logits = model(img)  # [1, num_classes]\n",
    "    probs = torch.softmax(logits, dim=1)[0]  # [num_classes]\n",
    "\n",
    "    conf, pred_idx = torch.max(probs, dim=0)\n",
    "    label = classes[pred_idx.item()]\n",
    "    return label, conf.item()\n",
    "\n",
    "\n",
    "def main():\n",
    "    print(\"Loading model...\")\n",
    "    model, classes = load_model()\n",
    "    print(\"Model loaded. Opening camera...\")\n",
    "\n",
    "    cap = cv2.VideoCapture(0)  # 0 = default camera\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        return\n",
    "\n",
    "    print(\"Press 'q' to quit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Predict on current frame\n",
    "        label, conf = predict_frame(model, classes, frame)\n",
    "\n",
    "        # Draw prediction on the frame\n",
    "        text = f\"{label} ({conf*100:.1f}%)\"\n",
    "        cv2.putText(\n",
    "            frame, text,\n",
    "            (10, 30),                  # position\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,  # font\n",
    "            1.0,                       # font scale\n",
    "            (0, 255, 0),               # color (B, G, R)\n",
    "            2,                         # thickness\n",
    "            cv2.LINE_AA\n",
    "        )\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow(\"Live Prediction\", frame)\n",
    "\n",
    "        # If user presses 'q' → quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
